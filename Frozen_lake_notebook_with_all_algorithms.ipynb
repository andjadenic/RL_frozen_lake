{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NPoZThMIlXyy",
        "yaf6ZRoQmIDw",
        "JpE959M-UXFP",
        "GOcSmeP9yX1O",
        "NEvudnTKSEPu",
        "5TorP-4vR95a",
        "HKIVn83U-Ptz",
        "SNpgI3Bc-WjI",
        "OP3Xb4uNQRPX",
        "bFAvJtOq-9yR",
        "VKWUARzmQ0IE",
        "QvgPy3nrRF3e",
        "Y5wMYWybRGyQ",
        "agBS0BSERGyS",
        "mOXKt_c_RO_-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Frozen Lake"
      ],
      "metadata": {
        "id": "6hem9FI1PZI4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "0TJZ9gs4PdCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYqEQ-EfPyDv",
        "outputId": "12250636-2358-48fa-a831-6617da2190b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/953.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m368.6/953.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m952.3/953.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.9.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "import gymnasium as gym\n",
        "import random\n",
        "import copy"
      ],
      "metadata": {
        "id": "evcD2mzAPcRi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample an episode\n",
        "\n",
        "\n",
        "function simulates a single episode of a game following the given policy pi\n",
        "\n",
        "INPUTS\n",
        "\n",
        "\n",
        "- pi: (16, 4) numpy array\n",
        "    - pi[s, a] is probability of agent taking action a given he is in state s\n",
        "    - for given s: we choose actions 0, 1, 2, 3 with probabilities pi[s, 0], pi[s, 1], pi[s, 2], pi[s, 3], respectively\n",
        "\n",
        "\n",
        "OPUTPUTS:\n",
        "\n",
        "    \n",
        "- episode: named tuple that collects trajectory information {s0, a0, r0, ..., s_T, a_T, r_T}\n",
        "  - single episode has form: episode(states=[0, 1, 2], actions=[1, 2, 3], rewards=[0, 0, 1], terminated=True, truncated=False)\n",
        "    "
      ],
      "metadata": {
        "id": "NPoZThMIlXyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episode = namedtuple('episode',\n",
        "                     'states, actions, rewards, terminated, truncated')"
      ],
      "metadata": {
        "id": "GOmHFPKsPuKR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_episode(pi: np.ndarray = 0.25 * np.ones((16, 4)), is_slippery_bool: bool = True) -> episode:\n",
        "    env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=is_slippery_bool)\n",
        "\n",
        "    s, info = env.reset(seed=42)\n",
        "    terminated, truncated = False, False\n",
        "    states, actions, rewards = [], [], []\n",
        "    while not truncated and not terminated:\n",
        "        a = np.random.choice([0, 1, 2, 3], p=pi[s, :])\n",
        "        s_new, r, terminated, truncated, _ = env.step(a)\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        rewards.append(r)\n",
        "        s = s_new\n",
        "    env.close()\n",
        "    return episode(states, actions, rewards, terminated, truncated)"
      ],
      "metadata": {
        "id": "pvsde4MsP1_P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize policy and q value"
      ],
      "metadata": {
        "id": "yaf6ZRoQmIDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_result(matrix: np.ndarray, text: str):\n",
        "    # Define actions and their corresponding arrow directions\n",
        "    actions = ['left', 'down', 'right', 'up']\n",
        "    dx = [-1, 0, 1, 0]\n",
        "    dy = [0, -1, 0, 1]\n",
        "\n",
        "    # Create a 4x4 plot\n",
        "    fig, axs = plt.subplots(4, 4, figsize=(10, 10))\n",
        "    fig.suptitle(f'{text}', ha='center', fontsize=16)\n",
        "\n",
        "    # Iterate through the matrix and plot arrows\n",
        "    for idx, cell in enumerate(matrix):\n",
        "        i, j = divmod(idx, 4)\n",
        "        max_prob = np.max(cell)\n",
        "        for action, p in enumerate(cell):\n",
        "            color = 'red' if p == max_prob else 'black'\n",
        "            axs[i, j].arrow(0.5, 0.5, dx[action] * 0.2 * p, dy[action] * 0.2 * p, head_width=0.05, head_length=0.1,\n",
        "                            fc=color, ec=color)\n",
        "            axs[i, j].text(0.5 + dx[action] * 0.3, 0.5 + dy[action] * 0.3, f'{p:.2f}', color=color, fontsize=12)\n",
        "        axs[i, j].set_xlim(0, 1)\n",
        "        axs[i, j].set_ylim(0, 1)\n",
        "        axs[i, j].axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "HwmBnV10mTfn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate mean return of a given policy"
      ],
      "metadata": {
        "id": "QrAd1G2zmZDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mean_return(pi: np.ndarray,\n",
        "                          N_runs: int = 50000, gamma: float = 0.9,\n",
        "                          is_slippery_bool: bool = False):\n",
        "    env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=is_slippery_bool)\n",
        "    mean_return = 0\n",
        "    s, _ = env.reset(seed=42)\n",
        "    for n_run in range(N_runs):\n",
        "        terminated, truncated = False, False\n",
        "        discount_factor = 1\n",
        "        while not terminated and not truncated:\n",
        "            a = np.argmax(pi[s, :])\n",
        "            new_s, r, terminated, truncated, _ = env.step(a)\n",
        "            mean_return += discount_factor * r\n",
        "            discount_factor *= gamma\n",
        "            s = new_s\n",
        "        s, _ = env.reset()\n",
        "    env.close()\n",
        "    mean_return /= N_runs\n",
        "    return mean_return"
      ],
      "metadata": {
        "id": "xpAgO2qJmeu_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert policy from exporatory to greedy"
      ],
      "metadata": {
        "id": "10zuBgYT7Jes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def policy2greedy(pi: np.ndarray):\n",
        "    greedy_policy = np.zeros_like(pi)\n",
        "    for s in range(15):\n",
        "        max_val = np.max(pi[s, :])\n",
        "        greedy_actions=[]\n",
        "        for a in range(4):\n",
        "            if pi[s, a] == max_val:\n",
        "                greedy_actions.append(a)\n",
        "        greedy_policy[s, greedy_actions] = 1 / len(greedy_actions)\n",
        "    return greedy_policy"
      ],
      "metadata": {
        "id": "HMsPpA8u7Noq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithms"
      ],
      "metadata": {
        "id": "SGY4FLO7o_gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random policy"
      ],
      "metadata": {
        "id": "JpE959M-UXFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pi = 0.25 * np.ones((16, 4))"
      ],
      "metadata": {
        "id": "-L24ne6sUZX4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi, N_runs=50000, gamma=1, is_slippery_bool=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3frJPab7UsvG",
        "outputId": "473e243f-c7cd-465a-a382-534a6496f12d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi, N_runs=50000, gamma=1, is_slippery_bool=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYJjAYslVG1I",
        "outputId": "16c5c146-3c5d-4667-8056-784f96cb8435"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic Programing"
      ],
      "metadata": {
        "id": "GOcSmeP9yX1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Policy evaluation"
      ],
      "metadata": {
        "id": "NEvudnTKSEPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_evaluation(P: dict, pi: np.ndarray, gamma: float = .9, theta: float = 1e-8):\n",
        "    v = np.zeros((16,))\n",
        "\n",
        "    # in-place policy evaluation\n",
        "    max_diff = 1e10\n",
        "    while max_diff > theta:\n",
        "        max_diff = 0\n",
        "        for s in range(15):\n",
        "            vs = 0\n",
        "            for a in range(4):\n",
        "                for prob, s_new, r, _ in P[s][a]:\n",
        "                    vs += pi[s, a]* prob * (r + gamma * v[s_new])\n",
        "\n",
        "            max_diff = max(abs(v[s] - vs), max_diff)\n",
        "            v[s] = vs\n",
        "    return v"
      ],
      "metadata": {
        "id": "9MZhnvVLyWEU"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def q_value(P: dict, v: np.ndarray, s: int, gamma: float = 1):\n",
        "    q = np.zeros((4, ))\n",
        "    for a in range(4):\n",
        "        for prob, s_new, r, _ in P[s][a]:\n",
        "            q[a] += prob * (r + gamma * v[s_new])\n",
        "    return q"
      ],
      "metadata": {
        "id": "gLffxgvdIstj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Policy iteration"
      ],
      "metadata": {
        "id": "5TorP-4vR95a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_iteration(P: dict, pi: np.ndarray = 0.25 * np.ones((16, 4)),\n",
        "                     theta: float = 1e-8, gamma: float = 0.9):\n",
        "    converge = False\n",
        "    q = np.zeros((16, 4))\n",
        "    while not converge:\n",
        "        # 1. policy evaluation\n",
        "        v = policy_evaluation(P, pi, gamma=gamma, theta=theta)\n",
        "\n",
        "        # 2. policy improvement\n",
        "        pi_prim = np.zeros((16, 4))\n",
        "        for s in range(15):\n",
        "            q[s] = q_value(P, v, s, gamma)\n",
        "            max_el = np.max(q[s])\n",
        "            greedy_actions = []\n",
        "            for a in range(4):\n",
        "                if q[s][a] == max_el:\n",
        "                    greedy_actions.append(a)\n",
        "            pi_prim[s, greedy_actions] = 1 / len(greedy_actions)\n",
        "\n",
        "        # 3. stop if pi converged\n",
        "        if np.max(abs(policy_evaluation(P, pi)[0] - policy_evaluation(P, pi_prim)[0])) < theta * 1e2:\n",
        "            converge = True\n",
        "\n",
        "        # 4. Replace policy with new policy\n",
        "        pi = copy.copy(pi_prim)\n",
        "\n",
        "    pi = policy2greedy(pi)\n",
        "    return pi, v, q"
      ],
      "metadata": {
        "id": "_yAeB2F6NQUJ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-slipery Frozen Lake"
      ],
      "metadata": {
        "id": "HKIVn83U-Ptz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=False)\n",
        "P = env.P\n",
        "env.close()"
      ],
      "metadata": {
        "id": "yDuZQgU-zlvG"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi_dp, v_dp, q_dp = policy_iteration(P=P, theta = 1e-8, gamma = 0.9)"
      ],
      "metadata": {
        "id": "M2_GlKbj-Kut"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_dp, N_runs=50000, gamma = .9, is_slippery_bool=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAsiLPDY6i0P",
        "outputId": "dd4cff5c-bc93-48d8-a4d7-b344d83a9084"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5904899999995002"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Slipery Frozen Lake"
      ],
      "metadata": {
        "id": "SNpgI3Bc-WjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=True)\n",
        "P = env.P\n",
        "env.close()"
      ],
      "metadata": {
        "id": "37RJoUNA-WjI"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pi_dp, v_dp, q_dp = policy_iteration(P=P, theta = 1e-8, gamma = 0.9)"
      ],
      "metadata": {
        "id": "-wj7MsI8-WjJ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_dp, N_runs=50000, gamma = .9, is_slippery_bool=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWYHf_lG-ptI",
        "outputId": "8521ef73-6719-4182-9850-2464fcea1bc2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06862379022899782"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monte Carlo\n"
      ],
      "metadata": {
        "id": "OP3Xb4uNQRPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def monte_carlo_control(N_episodes: int = 10, epsilon: float = 0.1, gamma: float = 0.9, is_slippery_bool: bool = True):\n",
        "    q = np.zeros((16, 4))\n",
        "    pi = .25 * np.ones((16, 4))\n",
        "\n",
        "    for n_episode in range(1, N_episodes + 1):\n",
        "\n",
        "        trajectory = sample_episode(pi=pi, is_slippery_bool=is_slippery_bool)\n",
        "\n",
        "        G = 0\n",
        "        for step in reversed(range(len(trajectory.states))):  # start from the last step\n",
        "            s, a, r = trajectory.states[step], trajectory.actions[step], trajectory.rewards[step]\n",
        "\n",
        "            first_visit = True\n",
        "            for s_prev, a_prev in zip(trajectory.states[0:step-1], trajectory.actions[0:step-1]):\n",
        "                if s_prev == s and a_prev == a:\n",
        "                    first_visit = False\n",
        "\n",
        "            if first_visit:\n",
        "                G = r + gamma * G\n",
        "                q[s, a] += (G - q[s, a]) / n_episode\n",
        "\n",
        "                a_star = np.max(q[s, :])\n",
        "                greedy_actions = []\n",
        "                for i in range(4):\n",
        "                    if q[s, i] == a_star:\n",
        "                        greedy_actions.append(i)\n",
        "                greedy_action = random.choice(greedy_actions)\n",
        "                pi[s, :] = epsilon / 4\n",
        "                pi[s, greedy_action] += 1 - epsilon\n",
        "    pi = policy2greedy(pi=pi)\n",
        "    return pi, q"
      ],
      "metadata": {
        "id": "J_BHs7xVNgQr"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monte Carlo Non-slippery Frozen Lake"
      ],
      "metadata": {
        "id": "bFAvJtOq-9yR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_mc, pi_mc = monte_carlo_control(N_episodes=10000, epsilon=0.1, is_slippery_bool=False)"
      ],
      "metadata": {
        "id": "Ey6tZXG_0Ev3"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_mc, N_runs=50000, gamma=0.9, is_slippery_bool=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuXnLyda_drP",
        "outputId": "5f3306fe-597a-4fb9-a9bf-f694ef2d0eb2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5904900000000002"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Monte Carlo Slippery Frozen Lake"
      ],
      "metadata": {
        "id": "VKWUARzmQ0IE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_mc, pi_mc = monte_carlo_control(N_episodes=10000, epsilon=0.1, is_slippery_bool=True)"
      ],
      "metadata": {
        "id": "38cVjq_xQ0IP"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_mc, N_runs=50000, gamma=0.9, is_slippery_bool=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599fafd9-b77a-4cf8-b36c-d373124b07ea",
        "id": "Pok0MyyxQ0IP"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02308751716963706"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sarsa and Expected Sarsa"
      ],
      "metadata": {
        "id": "Pv62WaDIQvu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sarsa_control(expected_sarsa: bool = False,\n",
        "                  N_episodes: int = 1000,\n",
        "                  alpha: float = 0.1, epsilon: float = 0.1, gamma: float = 0.9,\n",
        "                  is_slippery_bool: bool = False):\n",
        "    q = np.zeros((16, 4))\n",
        "    pi = .25 * np.ones((16, 4))\n",
        "    env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=is_slippery_bool)\n",
        "    s, info = env.reset(seed=42)\n",
        "\n",
        "    for n_episode in range(1, N_episodes + 1):\n",
        "        a = np.random.choice([0, 1, 2, 3], p=pi[s, :])\n",
        "        terminated, truncated = False, False\n",
        "\n",
        "        while not terminated and not truncated:\n",
        "            # take action a and observe reward r, following state s_new (terminated, truncated)\n",
        "            s_new, r, terminated, truncated, _ = env.step(a)\n",
        "\n",
        "            # sample action a_new from s_new following current policy\n",
        "            a_new = np.random.choice([0, 1, 2, 3], p=pi[s_new, :])\n",
        "\n",
        "            if not expected_sarsa:\n",
        "                q[s, a] += alpha * (r + gamma * q[s_new, a_new] - q[s, a])\n",
        "            else:\n",
        "                expected_q = 0\n",
        "                for action in range(4):\n",
        "                    expected_q += pi[s_new, action] * q[s_new, action]\n",
        "                q[s, a] += alpha * (r + gamma * expected_q - q[s, a])\n",
        "\n",
        "            # update policy pi for state s\n",
        "            a_star = np.max(q[s, :])\n",
        "            greedy_actions = []\n",
        "            for i in range(4):\n",
        "                if q[s, i] == a_star:\n",
        "                    greedy_actions.append(i)\n",
        "            greedy_action = random.choice(greedy_actions)\n",
        "            pi[s, :] = epsilon / 4\n",
        "            pi[s, greedy_action] += 1 - epsilon\n",
        "\n",
        "            s = s_new\n",
        "            a = a_new\n",
        "\n",
        "        s, info = env.reset()\n",
        "\n",
        "    env.close()\n",
        "    pi = policy2greedy(pi)\n",
        "    return pi, q"
      ],
      "metadata": {
        "id": "6imEOxQfNnQV"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SARSA Non-slippery Frozen Lake"
      ],
      "metadata": {
        "id": "z-EQR0sBRF3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_sarsa, pi_sarsa = sarsa_control(expected_sarsa=False, N_episodes=10000, epsilon=0.1, is_slippery_bool=False)"
      ],
      "metadata": {
        "id": "VXyOsFspRF3d"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_sarsa, N_runs=50000, gamma=0.9, is_slippery_bool=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028274a8-1f1f-4f8a-f163-b0dae202a726",
        "id": "O5v3PRZARF3e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5904900000000002"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SARSA Slippery Frozen Lake"
      ],
      "metadata": {
        "id": "QvgPy3nrRF3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_sarsa, pi_sarsa = sarsa_control(expected_sarsa=False, N_episodes=10000, epsilon=0.1, is_slippery_bool=True)"
      ],
      "metadata": {
        "id": "WjYqWyPCRF3e"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_sarsa, N_runs=50000, gamma=0.9, is_slippery_bool=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fb2df74-74b8-4070-969b-8f7071d3b3ed",
        "id": "sviDED1dRF3f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06375893235768844"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expected SARSA Non-slippery Frozen Lake"
      ],
      "metadata": {
        "id": "Y5wMYWybRGyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_sarsa, pi_sarsa = sarsa_control(expected_sarsa=True, N_episodes=10000, epsilon=0.1, is_slippery_bool=False)"
      ],
      "metadata": {
        "id": "OOPtwW2lStFm"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_sarsa, N_runs=50000, gamma=0.9, is_slippery_bool=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3649e775-572a-4084-cb39-8f19aabd3879",
        "id": "-yn_g5eUStF3"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5904900000000002"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expected SARSA Slippery Frozen Lake"
      ],
      "metadata": {
        "id": "agBS0BSERGyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_sarsa, pi_sarsa = sarsa_control(expected_sarsa=True, N_episodes=10000, epsilon=0.1, is_slippery_bool=True)"
      ],
      "metadata": {
        "id": "4OPB874NS_3o"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_sarsa, N_runs=50000, gamma=0.9, is_slippery_bool=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b48d7063-6e02-4c4e-ff82-970638e74571",
        "id": "CgHMRIIMS_3p"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06375893235768844"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q-learning"
      ],
      "metadata": {
        "id": "mOXKt_c_RO_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def q_learning(N_episodes: int = 1000,\n",
        "               alpha: float = 0.01, epsilon: float = 0.1, gamma: float = 0.9,\n",
        "               is_slippery_bool: bool = False):\n",
        "    q = np.zeros((16, 4))\n",
        "    pi = .25 * np.ones((16, 4))\n",
        "    env = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=is_slippery_bool)\n",
        "    s, info = env.reset(seed=42)\n",
        "\n",
        "    for n_episode in range(1, N_episodes + 1):\n",
        "        terminated, truncated = False, False\n",
        "\n",
        "        while not terminated and not truncated:\n",
        "            # sample action a from state s following policy pi\n",
        "            a = np.random.choice([0, 1, 2, 3], p=pi[s, :])\n",
        "\n",
        "            # take action a and observe reward r, following state s_new (terminated, truncated)\n",
        "            s_new, r, terminated, truncated, _ = env.step(a)\n",
        "\n",
        "            # update q[s, a]\n",
        "            q_max = np.max(q[s_new, :])\n",
        "            greedy_actions = []\n",
        "            for action in range(4):\n",
        "                if q[s_new, action] == q_max:\n",
        "                    greedy_actions.append(action)\n",
        "            a_new_star = random.choice(greedy_actions)\n",
        "            q[s, a] = q[s, a] + alpha * (r + gamma * q[s_new, a_new_star] - q[s, a])\n",
        "\n",
        "            # update policy pi for state s\n",
        "            a_star = np.max(q[s, :])\n",
        "            greedy_actions = []\n",
        "            for action in range(4):\n",
        "                if q[s, action] == a_star:\n",
        "                    greedy_actions.append(action)\n",
        "            greedy_action = random.choice(greedy_actions)\n",
        "            pi[s, :] = epsilon / 4\n",
        "            pi[s, greedy_action] += 1 - epsilon\n",
        "\n",
        "            s = s_new\n",
        "\n",
        "        s, info = env.reset()\n",
        "\n",
        "    env.close()\n",
        "    pi = policy2greedy(pi)\n",
        "    return pi, q"
      ],
      "metadata": {
        "id": "stdaRAAUNsUK"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q-Learning Non-slippery Frozen Lake"
      ],
      "metadata": {
        "id": "BIGBoWyfRJBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_q, pi_q = q_learning(N_episodes=10000, epsilon=0.1, is_slippery_bool=False)"
      ],
      "metadata": {
        "id": "Np0vzad2RJBo"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_q, N_runs=50000, gamma=0.9, is_slippery_bool=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d20353-ff0f-46e9-d905-e3dcb6f0de7d",
        "id": "QzzVSof0RJBp"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5904900000000002"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q-Learning Slippery Frozen Lake"
      ],
      "metadata": {
        "id": "gzE-6bnNRJBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_q, pi_q = q_learning(N_episodes=10000, epsilon=0.4, is_slippery_bool=True)"
      ],
      "metadata": {
        "id": "4w1-y2rKRJBq"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_mean_return(pi=pi_q, N_runs=50000, gamma=0.9, is_slippery_bool=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fd758b2-aaa0-415c-ce67-af9944b62666",
        "id": "pV8dDQmmRJBq"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0483448778038524"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    }
  ]
}